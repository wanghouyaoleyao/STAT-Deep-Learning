{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKTRkfzB2meZ"
      },
      "source": [
        "## NLP "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcnlSCMGU5_f"
      },
      "source": [
        "### Installation and Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5aWmKGmFCVH",
        "outputId": "9d1a6434-9f24-461d-c05c-505811951361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install Magnitude on Google Colab\n",
        "! echo \"Installing Magnitude.... (please wait, can take a while)\"\n",
        "! (curl https://raw.githubusercontent.com/plasticityai/magnitude/master/install-colab.sh | /bin/bash 1>/dev/null 2>/dev/null)\n",
        "! echo \"Done installing Magnitude.\""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Magnitude.... (please wait, can take a while)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   137  100   137    0     0    825      0 --:--:-- --:--:-- --:--:--   820\n",
            "Done installing Magnitude.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXWJI0qyppnL"
      },
      "source": [
        "import data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNh9WBcYFCX3",
        "outputId": "796126a7-a398-429a-c1f2-d505cba55bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pymagnitude import *\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\") \n",
        "file_path = 'GoogleNews-vectors-negative300.magnitude'\n",
        "vectors = Magnitude(file_path)\n",
        "vectors.distance(\"cat\",\"dog\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.69145405"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohBW2I2HVC7R"
      },
      "source": [
        "### Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI3bXfFLYn4Z"
      },
      "source": [
        "1. What is the dimensionality of these word embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdMwL9oqYsbG",
        "outputId": "e54700c0-80dd-4034-f54b-555dc24ec1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectors.dim"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BqrK-K1oA2"
      },
      "source": [
        "The function above is to output the dimensions of vectors. And the result shows the dimensionality of these word embeddings is 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttQIuIq-ubf"
      },
      "source": [
        "2. What are the top-5 most similar words to picnic(not including picnic itself)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq0NzbUbFCc6",
        "outputId": "fdd693ea-b73c-4189-f5ee-4d2f65cbf903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectors.most_similar(\"picnic\", topn=5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('picnics', 0.7400875),\n",
              " ('picnic_lunch', 0.721374),\n",
              " ('Picnic', 0.700534),\n",
              " ('potluck_picnic', 0.6683274),\n",
              " ('picnic_supper', 0.65189123)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7eXIUBQ2Mqr"
      },
      "source": [
        "The function above is to output the most similar (nearest neighbors) keys (words) for a given key (word). From the code shown in the github, this most_similar function already excluded the given key (word) itself, so we can just simply run this function with topn = 5. And the result shows the top-5 most similar words to picnic are [picnics, picnic_lunch, Picnic, potluck_picnic and picnic_supper]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwctIYNa9FLB"
      },
      "source": [
        "3. According to the word embeddings, which of these words is not like the others? ['tissue' , 'papyrus' , 'manila' , 'newsprint' , 'parchment' , 'gazette']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZRla4Xu9JkA",
        "outputId": "860cbde4-bd28-4e74-a73e-374d738df04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vectors.doesnt_match(['tissue','papyrus','manila','newsprint','parchment','gazette']) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tissue'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MB0plIr3NY8"
      },
      "source": [
        "The function above is to find one key (word) in a given list which doesn't match the rest of keys (words) in this list. And the result shows the word 'tissue' in this given list is not like others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7GkPsCwlQ_Z"
      },
      "source": [
        "4. Solve the following analogy: leg is to jump as X is to throw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqT5lwWc_wG5",
        "outputId": "0b57a470-4b5a-4297-e4ed-e9278bd321bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vectors.most_similar(positive = ['throw','leg'], negative = ['jump'], topn = 1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forearm', 0.48294652)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQQvo--x3OEu"
      },
      "source": [
        "The function above is to find analogies by finding the most similar keys given positive and negative examples. \n",
        "\n",
        "The idea is: leg - jump = X - throw so by putting leg and throw in the positive list and jump in the negative list, we are able to find the corresponding key (word) to leg in the negative list which is forearm. \n",
        "\n",
        "So, leg is to jump as forearm is to throw."
      ]
    }
  ]
}